{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-16T11:16:02.540701Z","iopub.execute_input":"2022-11-16T11:16:02.541234Z","iopub.status.idle":"2022-11-16T11:16:02.606378Z","shell.execute_reply.started":"2022-11-16T11:16:02.541122Z","shell.execute_reply":"2022-11-16T11:16:02.605341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pathlib\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport os\nimport PIL\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nimport matplotlib.pyplot as plt\n","metadata":{"execution":{"iopub.status.busy":"2022-11-16T11:16:02.611310Z","iopub.execute_input":"2022-11-16T11:16:02.612816Z","iopub.status.idle":"2022-11-16T11:16:13.098521Z","shell.execute_reply.started":"2022-11-16T11:16:02.612773Z","shell.execute_reply":"2022-11-16T11:16:13.097466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!conda install -y gdown","metadata":{"execution":{"iopub.status.busy":"2022-11-16T11:16:13.099788Z","iopub.execute_input":"2022-11-16T11:16:13.100839Z","iopub.status.idle":"2022-11-16T11:17:43.605404Z","shell.execute_reply.started":"2022-11-16T11:16:13.100804Z","shell.execute_reply":"2022-11-16T11:17:43.604256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gdown\n\nurl = 'https://drive.google.com/file/d/1KY1eqXDMu4zPgT8B6Vx7MkJCYWsTNRRk'\n\noutput = 'file.zip'\n\ngdown.download(url, output, quiet=False)","metadata":{"execution":{"iopub.status.busy":"2022-11-16T11:17:43.609717Z","iopub.execute_input":"2022-11-16T11:17:43.610024Z","iopub.status.idle":"2022-11-16T11:17:44.427431Z","shell.execute_reply.started":"2022-11-16T11:17:43.609986Z","shell.execute_reply":"2022-11-16T11:17:44.426369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!gdown --id 1KY1eqXDMu4zPgT8B6Vx7MkJCYWsTNRRk","metadata":{"execution":{"iopub.status.busy":"2022-11-16T11:17:44.429011Z","iopub.execute_input":"2022-11-16T11:17:44.429669Z","iopub.status.idle":"2022-11-16T11:17:54.643790Z","shell.execute_reply.started":"2022-11-16T11:17:44.429630Z","shell.execute_reply":"2022-11-16T11:17:54.642454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.listdir()","metadata":{"execution":{"iopub.status.busy":"2022-11-16T11:17:54.648028Z","iopub.execute_input":"2022-11-16T11:17:54.648365Z","iopub.status.idle":"2022-11-16T11:17:54.658134Z","shell.execute_reply.started":"2022-11-16T11:17:54.648331Z","shell.execute_reply":"2022-11-16T11:17:54.657037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#extracting zip file\nimport zipfile\nz= zipfile.ZipFile('CNN_assignment.zip')\nz.extractall()","metadata":{"execution":{"iopub.status.busy":"2022-11-16T11:17:54.660222Z","iopub.execute_input":"2022-11-16T11:17:54.660815Z","iopub.status.idle":"2022-11-16T11:17:59.869897Z","shell.execute_reply.started":"2022-11-16T11:17:54.660774Z","shell.execute_reply":"2022-11-16T11:17:59.868474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pathlib.Path(\"Skin cancer ISIC The International Skin Imaging Collaboration/Train/\")\ntest = pathlib.Path(\"Skin cancer ISIC The International Skin Imaging Collaboration/Test/\")","metadata":{"execution":{"iopub.status.busy":"2022-11-16T11:17:59.876441Z","iopub.execute_input":"2022-11-16T11:17:59.877277Z","iopub.status.idle":"2022-11-16T11:17:59.889297Z","shell.execute_reply.started":"2022-11-16T11:17:59.877225Z","shell.execute_reply":"2022-11-16T11:17:59.887441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_count_train = len(list(train.glob('*/*.jpg')))\nprint('Images in training dataset: ',image_count_train)\nimage_count_test = len(list(test.glob('*/*.jpg')))\nprint('Images in testing dataset: ',image_count_test)","metadata":{"execution":{"iopub.status.busy":"2022-11-16T11:17:59.892007Z","iopub.execute_input":"2022-11-16T11:17:59.892956Z","iopub.status.idle":"2022-11-16T11:17:59.941095Z","shell.execute_reply.started":"2022-11-16T11:17:59.892899Z","shell.execute_reply":"2022-11-16T11:17:59.939841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\nimg_height = 180\nimg_width = 180","metadata":{"execution":{"iopub.status.busy":"2022-11-16T11:17:59.952403Z","iopub.execute_input":"2022-11-16T11:17:59.955694Z","iopub.status.idle":"2022-11-16T11:17:59.963634Z","shell.execute_reply.started":"2022-11-16T11:17:59.955645Z","shell.execute_reply":"2022-11-16T11:17:59.961989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Creating train and validation dataset","metadata":{}},{"cell_type":"code","source":"train_ds = tf.keras.utils.image_dataset_from_directory(\n            train,\n            batch_size=batch_size,\n            image_size=(img_height, img_width),\n            seed=123,\n            validation_split=0.2,\n            subset='training',\n            )","metadata":{"execution":{"iopub.status.busy":"2022-11-16T11:17:59.965103Z","iopub.execute_input":"2022-11-16T11:17:59.965594Z","iopub.status.idle":"2022-11-16T11:18:07.095526Z","shell.execute_reply.started":"2022-11-16T11:17:59.965557Z","shell.execute_reply":"2022-11-16T11:18:07.094426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_ds = tf.keras.utils.image_dataset_from_directory(\n            train,\n            batch_size=batch_size,\n            image_size=(img_height, img_width),\n            seed=123,\n            validation_split=0.2,\n            subset='validation',\n            )","metadata":{"execution":{"iopub.status.busy":"2022-11-16T11:18:07.096877Z","iopub.execute_input":"2022-11-16T11:18:07.097942Z","iopub.status.idle":"2022-11-16T11:18:07.323227Z","shell.execute_reply.started":"2022-11-16T11:18:07.097899Z","shell.execute_reply":"2022-11-16T11:18:07.322176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names = train_ds.class_names\nprint(class_names)","metadata":{"execution":{"iopub.status.busy":"2022-11-16T11:18:07.325601Z","iopub.execute_input":"2022-11-16T11:18:07.326231Z","iopub.status.idle":"2022-11-16T11:18:07.332393Z","shell.execute_reply.started":"2022-11-16T11:18:07.326188Z","shell.execute_reply":"2022-11-16T11:18:07.331027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualizing one instance of all the nine classes present in the dataset","metadata":{}},{"cell_type":"code","source":"for images, labels in train_ds:\n    unique_li = []\n    unique_images = []\n    for i in range(32):\n        if class_names[labels[i]] not in unique_li:\n            unique_li.append(class_names[labels[i]])\n            unique_images.append((class_names[labels[i]],images[i]))","metadata":{"execution":{"iopub.status.busy":"2022-11-16T11:18:07.334110Z","iopub.execute_input":"2022-11-16T11:18:07.334790Z","iopub.status.idle":"2022-11-16T11:18:17.578589Z","shell.execute_reply.started":"2022-11-16T11:18:07.334750Z","shell.execute_reply":"2022-11-16T11:18:17.577566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unique_li","metadata":{"execution":{"iopub.status.busy":"2022-11-16T11:18:17.580055Z","iopub.execute_input":"2022-11-16T11:18:17.580400Z","iopub.status.idle":"2022-11-16T11:18:17.588103Z","shell.execute_reply.started":"2022-11-16T11:18:17.580364Z","shell.execute_reply":"2022-11-16T11:18:17.587011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 10))\nfor i in range(9):\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(unique_images[i][1].numpy().astype(\"uint8\"))\n    plt.title(unique_images[i][0])\n    plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2022-11-16T11:18:17.589808Z","iopub.execute_input":"2022-11-16T11:18:17.590472Z","iopub.status.idle":"2022-11-16T11:18:18.383432Z","shell.execute_reply.started":"2022-11-16T11:18:17.590435Z","shell.execute_reply":"2022-11-16T11:18:18.382306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"AUTOTUNE = tf.data.experimental.AUTOTUNE\ntrain_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\nval_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2022-11-16T11:18:18.384596Z","iopub.execute_input":"2022-11-16T11:18:18.386832Z","iopub.status.idle":"2022-11-16T11:18:18.397257Z","shell.execute_reply.started":"2022-11-16T11:18:18.386776Z","shell.execute_reply":"2022-11-16T11:18:18.395548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model 1 - using dropout","metadata":{}},{"cell_type":"code","source":"num_class = 9\nimg_size = 180\nmodel = Sequential([\n    layers.experimental.preprocessing.Rescaling(1./255,input_shape=(img_height, img_width, 3)),\n    layers.experimental.preprocessing.Resizing(img_size, img_size),# Resizing the image to 180x180\n    layers.Conv2D(16, 3, padding='same', activation='relu'),\n    layers.MaxPooling2D(),\n    layers.Dropout(0.25),\n    layers.Conv2D(32, 3, padding='same', activation='relu'),\n    layers.MaxPooling2D(),\n    layers.Dropout(0.25),\n    layers.Conv2D(64, 3, padding='same', activation='relu'),\n    layers.MaxPooling2D(),\n    layers.Dropout(0.25),\n    layers.Flatten(),\n    layers.Dense(128, activation='relu'),\n    layers.Dense(num_class,activation='softmax')\n])","metadata":{"execution":{"iopub.status.busy":"2022-11-16T11:18:18.399552Z","iopub.execute_input":"2022-11-16T11:18:18.400382Z","iopub.status.idle":"2022-11-16T11:18:18.527133Z","shell.execute_reply.started":"2022-11-16T11:18:18.400343Z","shell.execute_reply":"2022-11-16T11:18:18.526119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-11-16T11:18:18.528446Z","iopub.execute_input":"2022-11-16T11:18:18.528848Z","iopub.status.idle":"2022-11-16T11:18:18.543874Z","shell.execute_reply.started":"2022-11-16T11:18:18.528810Z","shell.execute_reply":"2022-11-16T11:18:18.542954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 20\nhistory = model.fit(\n  train_ds,\n  validation_data=val_ds,\n  epochs=epochs\n)","metadata":{"execution":{"iopub.status.busy":"2022-11-16T11:18:18.545947Z","iopub.execute_input":"2022-11-16T11:18:18.546359Z","iopub.status.idle":"2022-11-16T11:19:13.813392Z","shell.execute_reply.started":"2022-11-16T11:18:18.546299Z","shell.execute_reply":"2022-11-16T11:19:13.812249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-11-16T11:19:13.815108Z","iopub.execute_input":"2022-11-16T11:19:13.815461Z","iopub.status.idle":"2022-11-16T11:19:13.825431Z","shell.execute_reply.started":"2022-11-16T11:19:13.815422Z","shell.execute_reply":"2022-11-16T11:19:13.822396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-16T11:19:13.827335Z","iopub.execute_input":"2022-11-16T11:19:13.827792Z","iopub.status.idle":"2022-11-16T11:19:14.153415Z","shell.execute_reply.started":"2022-11-16T11:19:13.827756Z","shell.execute_reply":"2022-11-16T11:19:14.152473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_results_df = pd.DataFrame(data=[{\"Type\":\"Model1 using Dropout\",\"Training Accuracy\":acc[-1],\"Validation Accuracy\":val_acc[-1],\"Epochs\":epochs}])\naccuracy_results_df","metadata":{"execution":{"iopub.status.busy":"2022-11-16T11:19:14.154913Z","iopub.execute_input":"2022-11-16T11:19:14.155255Z","iopub.status.idle":"2022-11-16T11:19:14.184001Z","shell.execute_reply.started":"2022-11-16T11:19:14.155218Z","shell.execute_reply":"2022-11-16T11:19:14.182553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations on model1 :**\n- The training accuracy at the end we got is 70% and validation accuracy is 52%. Since there is huge gap between training and validation accuracy, the model will not perform well on newer dataset.\n- As we can see from the plot that as the number of epochs increases, the training accuracy also increased but the validation accuracy reduced. This is clear case of overfitting.\n- We can also see that training loss decreased and validation loss increased with the number of epochs.","metadata":{}},{"cell_type":"markdown","source":"### Data augmentation","metadata":{}},{"cell_type":"code","source":"data_augmentation = tf.keras.Sequential([\n  layers.experimental.preprocessing.RandomRotation(0.2)\n])","metadata":{"execution":{"iopub.status.busy":"2022-11-16T11:19:14.186432Z","iopub.execute_input":"2022-11-16T11:19:14.187027Z","iopub.status.idle":"2022-11-16T11:19:14.197911Z","shell.execute_reply.started":"2022-11-16T11:19:14.186991Z","shell.execute_reply":"2022-11-16T11:19:14.196910Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\nimage = tf.expand_dims(unique_images[random.randint(0,9)][1], 0)\nplt.imshow(image[0].numpy().astype(\"uint8\"))\nplt.title(\"Original Image\")\nplt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2022-11-16T11:21:42.990559Z","iopub.execute_input":"2022-11-16T11:21:42.991015Z","iopub.status.idle":"2022-11-16T11:21:43.185672Z","shell.execute_reply.started":"2022-11-16T11:21:42.990977Z","shell.execute_reply":"2022-11-16T11:21:43.184573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"augmented_image = data_augmentation(image)\nplt.figure(figsize=(10, 10))\nfor i in range(16):\n    augmented_image = data_augmentation(image)\n    ax = plt.subplot(4, 4, i + 1)\n    plt.imshow(augmented_image[0].numpy().astype(\"uint8\"))\n    plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2022-11-16T11:21:44.614244Z","iopub.execute_input":"2022-11-16T11:21:44.614749Z","iopub.status.idle":"2022-11-16T11:21:46.391044Z","shell.execute_reply.started":"2022-11-16T11:21:44.614707Z","shell.execute_reply":"2022-11-16T11:21:46.390024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- We can see that slight rotations are applied to the images using the data augmentation\n","metadata":{}},{"cell_type":"code","source":"num_class = 9\nimg_size = 180\nmodel_data = Sequential([\n    layers.experimental.preprocessing.Rescaling(1./255,input_shape=(img_height, img_width, 3)),\n    layers.experimental.preprocessing.Resizing(img_size, img_size),# Resizing the image to 180x180\n    data_augmentation,\n    layers.Conv2D(16, 3, padding='same', activation='relu'),\n    layers.MaxPooling2D(),\n    layers.Dropout(0.25),\n    layers.Conv2D(32, 3, padding='same', activation='relu'),\n    layers.MaxPooling2D(),\n    layers.Dropout(0.25),\n    layers.Conv2D(64, 3, padding='same', activation='relu'),\n    layers.MaxPooling2D(),\n    layers.Dropout(0.25),\n    layers.Flatten(),\n    layers.Dense(128, activation='relu'),\n    layers.Dense(num_class,activation='softmax')\n])","metadata":{"execution":{"iopub.status.busy":"2022-11-16T11:21:46.393272Z","iopub.execute_input":"2022-11-16T11:21:46.393995Z","iopub.status.idle":"2022-11-16T11:21:46.651893Z","shell.execute_reply.started":"2022-11-16T11:21:46.393949Z","shell.execute_reply":"2022-11-16T11:21:46.650722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_data.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'],\n              )\nmodel_data.summary()","metadata":{"execution":{"iopub.status.busy":"2022-11-16T11:21:46.656995Z","iopub.execute_input":"2022-11-16T11:21:46.659986Z","iopub.status.idle":"2022-11-16T11:21:46.681214Z","shell.execute_reply.started":"2022-11-16T11:21:46.659940Z","shell.execute_reply":"2022-11-16T11:21:46.679840Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 20\n# Lets the fit the model with batch size of 32 and 20 epochs\nhistory_data = model_data.fit(\n  train_ds,\n  validation_data=val_ds,\n  epochs=epochs,\n  batch_size=32\n)","metadata":{"execution":{"iopub.status.busy":"2022-11-16T11:21:46.684117Z","iopub.execute_input":"2022-11-16T11:21:46.686914Z","iopub.status.idle":"2022-11-16T11:22:25.266642Z","shell.execute_reply.started":"2022-11-16T11:21:46.686871Z","shell.execute_reply":"2022-11-16T11:22:25.265572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = history_data.history['accuracy']\nval_acc = history_data.history['val_accuracy']\n\nloss = history_data.history['loss']\nval_loss = history_data.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-16T11:22:25.268453Z","iopub.execute_input":"2022-11-16T11:22:25.268787Z","iopub.status.idle":"2022-11-16T11:22:25.594401Z","shell.execute_reply.started":"2022-11-16T11:22:25.268758Z","shell.execute_reply":"2022-11-16T11:22:25.593419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_results_df = accuracy_results_df.append([{\"Type\":\"Model2 using Data Augmentation\",\"Training Accuracy\":acc[-1],\"Validation Accuracy\":val_acc[-1],\"Epochs\":epochs}])\naccuracy_results_df","metadata":{"execution":{"iopub.status.busy":"2022-11-16T11:22:25.596113Z","iopub.execute_input":"2022-11-16T11:22:25.596809Z","iopub.status.idle":"2022-11-16T11:22:25.621516Z","shell.execute_reply.started":"2022-11-16T11:22:25.596769Z","shell.execute_reply":"2022-11-16T11:22:25.620455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations on model2 - Model using Data augmentaion**\n- We can observe that training and validation accuracy are almost similar, hence overfitting issue has resolved.\n- But we can see that accuracy is around 50% which is very low.","metadata":{}},{"cell_type":"markdown","source":"### Checking distribution of classes in the training dataset","metadata":{}},{"cell_type":"code","source":"\nclasses_dict={}\n# Go through all training dataset batches\nfor image_batch, labels_batch in train_ds:\n  # prepare the count of images in each class\n    for i in range(image_batch.shape[0]):\n        if class_names[labels_batch[i]] in classes_dict:\n            classes_dict[class_names[labels_batch[i]]]+=1\n        else:\n            classes_dict[class_names[labels_batch[i]]]=1","metadata":{"execution":{"iopub.status.busy":"2022-11-16T11:22:25.622769Z","iopub.execute_input":"2022-11-16T11:22:25.623146Z","iopub.status.idle":"2022-11-16T11:22:26.140788Z","shell.execute_reply.started":"2022-11-16T11:22:25.623106Z","shell.execute_reply":"2022-11-16T11:22:26.139576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes_dict","metadata":{"execution":{"iopub.status.busy":"2022-11-16T11:22:26.143823Z","iopub.execute_input":"2022-11-16T11:22:26.144731Z","iopub.status.idle":"2022-11-16T11:22:26.152537Z","shell.execute_reply.started":"2022-11-16T11:22:26.144690Z","shell.execute_reply":"2022-11-16T11:22:26.151288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class distribution in Dataframe\ndf_distr = pd.DataFrame({\"Class Name\":classes_dict.keys(), \"Samples\":classes_dict.values()})\ndf_distr.sort_values('Samples',ascending=False)","metadata":{"execution":{"iopub.status.busy":"2022-11-16T11:22:26.154329Z","iopub.execute_input":"2022-11-16T11:22:26.154834Z","iopub.status.idle":"2022-11-16T11:22:26.187982Z","shell.execute_reply.started":"2022-11-16T11:22:26.154793Z","shell.execute_reply":"2022-11-16T11:22:26.186814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualizing class distribution","metadata":{}},{"cell_type":"code","source":"# Lets visualize Class Distribution\nimport seaborn as sns\nplt.figure(figsize=(10, 10))\nsns.barplot(data=df_distr,x='Class Name',y='Samples',palette='pastel')\nplt.xticks(rotation = 90) \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-16T11:22:26.195799Z","iopub.execute_input":"2022-11-16T11:22:26.196541Z","iopub.status.idle":"2022-11-16T11:22:27.038594Z","shell.execute_reply.started":"2022-11-16T11:22:26.196484Z","shell.execute_reply":"2022-11-16T11:22:27.037537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations on Class Imbalance :**\n- Which class has the least number of samples?\n> seborrheic keratosis\n\n- Which classes dominate the data in terms proportionate number of samples?\n> pigmented benign keratosis","metadata":{}},{"cell_type":"markdown","source":"### Rectifying the class imbalance ","metadata":{}},{"cell_type":"code","source":"!pip install Augmentor","metadata":{"execution":{"iopub.status.busy":"2022-11-16T11:22:27.040268Z","iopub.execute_input":"2022-11-16T11:22:27.040694Z","iopub.status.idle":"2022-11-16T11:22:39.932909Z","shell.execute_reply.started":"2022-11-16T11:22:27.040653Z","shell.execute_reply":"2022-11-16T11:22:39.931532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path_to_training_dataset=\"Skin cancer ISIC The International Skin Imaging Collaboration/Train/\"\nimport Augmentor\nfor i in class_names:\n    p = Augmentor.Pipeline(path_to_training_dataset + i)\n    p.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)\n    p.sample(500) ## We are adding 500 samples per class to make sure that none of the classes are sparse.","metadata":{"execution":{"iopub.status.busy":"2022-11-16T11:22:39.934907Z","iopub.execute_input":"2022-11-16T11:22:39.935661Z","iopub.status.idle":"2022-11-16T11:28:16.947751Z","shell.execute_reply.started":"2022-11-16T11:22:39.935614Z","shell.execute_reply":"2022-11-16T11:28:16.946826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_count_train = len(list(train.glob('*/output/*.jpg')))\nprint(image_count_train)","metadata":{"execution":{"iopub.status.busy":"2022-11-16T11:28:16.949276Z","iopub.execute_input":"2022-11-16T11:28:16.949711Z","iopub.status.idle":"2022-11-16T11:28:17.233232Z","shell.execute_reply.started":"2022-11-16T11:28:16.949668Z","shell.execute_reply":"2022-11-16T11:28:17.232206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Lets see the distribution of augmented data after adding new images to the original training data.","metadata":{}},{"cell_type":"code","source":"path_list = [x for x in train.glob(os.path.join('*','output', '*.jpg'))]","metadata":{"execution":{"iopub.status.busy":"2022-11-16T11:28:17.235001Z","iopub.execute_input":"2022-11-16T11:28:17.235388Z","iopub.status.idle":"2022-11-16T11:28:17.262889Z","shell.execute_reply.started":"2022-11-16T11:28:17.235349Z","shell.execute_reply":"2022-11-16T11:28:17.261984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lesion_list_new = [os.path.basename(os.path.dirname(os.path.dirname(y))) for y in train.glob(os.path.join('*','output', '*.jpg'))]","metadata":{"execution":{"iopub.status.busy":"2022-11-16T11:28:17.264337Z","iopub.execute_input":"2022-11-16T11:28:17.264981Z","iopub.status.idle":"2022-11-16T11:28:17.313316Z","shell.execute_reply.started":"2022-11-16T11:28:17.264943Z","shell.execute_reply":"2022-11-16T11:28:17.312363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataframe_dict_new = dict(zip(path_list, lesion_list_new))","metadata":{"execution":{"iopub.status.busy":"2022-11-16T11:28:17.314788Z","iopub.execute_input":"2022-11-16T11:28:17.315168Z","iopub.status.idle":"2022-11-16T11:28:17.327652Z","shell.execute_reply.started":"2022-11-16T11:28:17.315132Z","shell.execute_reply":"2022-11-16T11:28:17.326565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_augmentator = pd.DataFrame(list(dataframe_dict_new.items()),columns = ['Path','Label'])\ndf_augmentator","metadata":{"execution":{"iopub.status.busy":"2022-11-16T11:28:17.329108Z","iopub.execute_input":"2022-11-16T11:28:17.329606Z","iopub.status.idle":"2022-11-16T11:28:17.353710Z","shell.execute_reply.started":"2022-11-16T11:28:17.329566Z","shell.execute_reply":"2022-11-16T11:28:17.352684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train the model on the data created using Augmentor","metadata":{}},{"cell_type":"code","source":"batch_size = 32\nimg_height = 180\nimg_width = 180","metadata":{"execution":{"iopub.status.busy":"2022-11-16T11:28:17.355244Z","iopub.execute_input":"2022-11-16T11:28:17.355611Z","iopub.status.idle":"2022-11-16T11:28:17.365010Z","shell.execute_reply.started":"2022-11-16T11:28:17.355576Z","shell.execute_reply":"2022-11-16T11:28:17.364007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir_train=\"Skin cancer ISIC The International Skin Imaging Collaboration/Train/\"\ntrain_ds_augmentor = tf.keras.preprocessing.image_dataset_from_directory(\n  data_dir_train,\n  seed=123,\n  validation_split = 0.2,\n  subset = \"training\",\n  image_size=(img_height, img_width),\n  batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-11-16T11:28:17.366317Z","iopub.execute_input":"2022-11-16T11:28:17.367004Z","iopub.status.idle":"2022-11-16T11:28:17.840042Z","shell.execute_reply.started":"2022-11-16T11:28:17.366735Z","shell.execute_reply":"2022-11-16T11:28:17.838880Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_ds_augmentor = tf.keras.preprocessing.image_dataset_from_directory(\n  data_dir_train,\n  seed=123,\n  validation_split = 0.2,\n  subset = \"validation\",\n  image_size=(img_height, img_width),\n  batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-11-16T11:28:17.841450Z","iopub.execute_input":"2022-11-16T11:28:17.842230Z","iopub.status.idle":"2022-11-16T11:28:18.309822Z","shell.execute_reply.started":"2022-11-16T11:28:17.842191Z","shell.execute_reply":"2022-11-16T11:28:18.308622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_class = 9\nimg_size = 180\nmodel_augmentor_bn = Sequential([\n    layers.experimental.preprocessing.Rescaling(1./255,input_shape=(img_height, img_width, 3)),\n    data_augmentation,\n    layers.Conv2D(16, 3, padding='same', activation='relu'),\n    layers.MaxPooling2D(),\n    layers.Dropout(0.2),\n    layers.Conv2D(32, 3, padding='same', activation='relu'),\n    layers.MaxPooling2D(),\n    layers.Dropout(0.2),\n    layers.Conv2D(64, 3, padding='same', activation='relu'),\n    layers.MaxPooling2D(),\n    layers.Dropout(0.2),\n    layers.Flatten(),\n    layers.Dense(128, activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dense(num_class,activation='softmax')\n])","metadata":{"execution":{"iopub.status.busy":"2022-11-16T11:28:18.313631Z","iopub.execute_input":"2022-11-16T11:28:18.314468Z","iopub.status.idle":"2022-11-16T11:28:18.501332Z","shell.execute_reply.started":"2022-11-16T11:28:18.314427Z","shell.execute_reply":"2022-11-16T11:28:18.500307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_augmentor_bn.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'],\n              )\nmodel_augmentor_bn.summary()","metadata":{"execution":{"iopub.status.busy":"2022-11-16T11:28:18.506011Z","iopub.execute_input":"2022-11-16T11:28:18.508747Z","iopub.status.idle":"2022-11-16T11:28:18.526277Z","shell.execute_reply.started":"2022-11-16T11:28:18.508704Z","shell.execute_reply":"2022-11-16T11:28:18.525212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.backend.clear_session()\n\nepochs = 30\n# Lets the fit the model with batch size of 32 and 30 epochs\nhistory_augmentor_bn = model_augmentor_bn.fit(\n  train_ds_augmentor,\n  validation_data=val_ds_augmentor,\n  epochs=epochs,\n  batch_size=32\n)","metadata":{"execution":{"iopub.status.busy":"2022-11-16T11:28:18.530068Z","iopub.execute_input":"2022-11-16T11:28:18.530853Z","iopub.status.idle":"2022-11-16T11:45:41.370472Z","shell.execute_reply.started":"2022-11-16T11:28:18.530818Z","shell.execute_reply":"2022-11-16T11:45:41.369557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = history_augmentor_bn.history['accuracy']\nval_acc = history_augmentor_bn.history['val_accuracy']\n\nloss = history_augmentor_bn.history['loss']\nval_loss = history_augmentor_bn.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-16T11:45:41.377579Z","iopub.execute_input":"2022-11-16T11:45:41.377887Z","iopub.status.idle":"2022-11-16T11:45:41.702457Z","shell.execute_reply.started":"2022-11-16T11:45:41.377858Z","shell.execute_reply":"2022-11-16T11:45:41.701453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_results_df = accuracy_results_df.append([{\"Type\":\"Model3 using Balanced data with Normalization\",\"Training Accuracy\":acc[-1],\"Validation Accuracy\":val_acc[-1],\"Epochs\":epochs}])\naccuracy_results_df","metadata":{"execution":{"iopub.status.busy":"2022-11-16T11:45:41.703954Z","iopub.execute_input":"2022-11-16T11:45:41.704306Z","iopub.status.idle":"2022-11-16T11:45:41.720133Z","shell.execute_reply.started":"2022-11-16T11:45:41.704264Z","shell.execute_reply":"2022-11-16T11:45:41.719078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations on model3 - Model using rectified data with Normalizationn**\n- The training accuracy at the end we got is 79% and validation accuracy is 75%. We can observe a rise in accuracy without causing overfitting.\n- We also observe in the graph that there are huge jerks in validation accuracy.","metadata":{}},{"cell_type":"code","source":"num_class = 9\nimg_size = 180\nmodel_augmentor = Sequential([\n    layers.experimental.preprocessing.Rescaling(1./255,input_shape=(img_height, img_width, 3)),\n    data_augmentation,\n    layers.Conv2D(16, 3, padding='same', activation='relu'),\n    layers.MaxPooling2D(),\n    layers.Dropout(0.25),\n#     layers.BatchNormalization(),\n    layers.Conv2D(32, 3, padding='same', activation='relu'),\n    layers.MaxPooling2D(),\n    layers.Dropout(0.25),\n#     layers.BatchNormalization(),\n    layers.Conv2D(64, 3, padding='same', activation='relu'),\n    layers.MaxPooling2D(),\n    layers.Dropout(0.25),\n    layers.Flatten(),\n    layers.Dense(128, activation='relu'),\n#     layers.BatchNormalization(),\n    layers.Dense(num_class,activation='softmax')\n])","metadata":{"execution":{"iopub.status.busy":"2022-11-16T11:45:41.721318Z","iopub.execute_input":"2022-11-16T11:45:41.721766Z","iopub.status.idle":"2022-11-16T11:45:41.847385Z","shell.execute_reply.started":"2022-11-16T11:45:41.721722Z","shell.execute_reply":"2022-11-16T11:45:41.846530Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_augmentor.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'],\n              )\nmodel_augmentor.summary()","metadata":{"execution":{"iopub.status.busy":"2022-11-16T11:45:41.848961Z","iopub.execute_input":"2022-11-16T11:45:41.849367Z","iopub.status.idle":"2022-11-16T11:45:41.862216Z","shell.execute_reply.started":"2022-11-16T11:45:41.849330Z","shell.execute_reply":"2022-11-16T11:45:41.860556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.backend.clear_session()\n\nepochs = 30\n# Lets the fit the model with batch size of 32 and 20 epochs\nhistory_augmentor = model_augmentor.fit(\n  train_ds_augmentor,\n  validation_data=val_ds_augmentor,\n  epochs=epochs,\n  batch_size=32\n)","metadata":{"execution":{"iopub.status.busy":"2022-11-16T11:45:41.867685Z","iopub.execute_input":"2022-11-16T11:45:41.867942Z","iopub.status.idle":"2022-11-16T12:02:15.094531Z","shell.execute_reply.started":"2022-11-16T11:45:41.867918Z","shell.execute_reply":"2022-11-16T12:02:15.093478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = history_augmentor.history['accuracy']\nval_acc = history_augmentor.history['val_accuracy']\n\nloss = history_augmentor.history['loss']\nval_loss = history_augmentor.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-16T12:02:15.096595Z","iopub.execute_input":"2022-11-16T12:02:15.096969Z","iopub.status.idle":"2022-11-16T12:02:15.448983Z","shell.execute_reply.started":"2022-11-16T12:02:15.096930Z","shell.execute_reply":"2022-11-16T12:02:15.447962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_results_df = accuracy_results_df.append([{\"Type\":\"Model4 using Balanced data and without Normalization\",\"Training Accuracy\":acc[-1],\"Validation Accuracy\":val_acc[-1],\"Epochs\":epochs}])\naccuracy_results_df","metadata":{"execution":{"iopub.status.busy":"2022-11-16T12:02:15.450471Z","iopub.execute_input":"2022-11-16T12:02:15.451793Z","iopub.status.idle":"2022-11-16T12:02:15.468214Z","shell.execute_reply.started":"2022-11-16T12:02:15.451747Z","shell.execute_reply":"2022-11-16T12:02:15.466919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations on model3 - Model using rectified data without Normalizationn**\n- The training accuracy at the end we got is 76% and validation accuracy is 73%.\n- We also observe in the graph that there are no huge jerks in validation accuracy.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}